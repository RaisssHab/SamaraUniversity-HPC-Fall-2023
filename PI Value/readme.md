<h1>PI Value</h1>
<h2>Постановка цели эксперимента</h2>

Цель – исследовать ускорение при вычислении числа PI на CUDA относительно последовательной реализации.

Задачи:
1.	Рассчитать время, достигаемое последовательной реализацией алгоритма.
2.	Рассчитать время и ускорение, достигаемое с использованием написанной параллельной реализации на CUDA.
3.	Проанализировать результат, сделать выводы.

<h2>Инструментальные средства эксперимента</h2>
<h3>Программные средства</h3>
Язык программирования – C++. 

Последовательные реализации:

С использованием if-конструкции:
```
double CPU_calc_with_if(double* xs, double* ys, int size) {
    double sum = 0;
    for (int i = 0; i < size; ++i) {
        double v = xs[i] * xs[i] + ys[i] * ys[i];
        if (v < 1) {
            ++sum;
        }
    }
    return sum * 4. / size;
}
```

Без использования if-конструкции:

```
double CPU_calc_without_if(double* xs, double* ys, int size) {
    double sum = 0;
    for (int i = 0; i < size; ++i) {
        double v = xs[i] * xs[i] + ys[i] * ys[i];
        sum += (v < 1);
    }
    return sum * 4. / size;
}
```

Полагается, что использование if может замедлять вычисления. Однако компилятор может нивелировать эту проблему.

Параллельные реализации:

Функция ядра с использованием if:

```
__global__ void kernelWithIf(double* xs, double* ys, int size) {
    unsigned int i = blockIdx.x * blockDim.x + threadIdx.x;
    if (i >= size) {
        return;
    }
    double x = xs[i];
    double y = ys[i];
    double v = x * x + y * y;
    if (v < 1) {
        xs[i] = 1;
    }
    else {
        xs[i] = 0;
    }
}
```

По аналогии - без использования if. 

Далее используется функция с использованием редукции на массиве:

```
void GPU_calc_with_if(double* xs, double* ys, int size)
{
    int gridSize = (size + 1023) / 1024;
    kernelWithIf <<< gridSize, 1024>>> (xs, ys, size);
    cudaError_t cuerr = cudaGetLastError();
    if (cuerr != cudaSuccess)
    {
        fprintf(stderr, "Cannot launch CUDA kernel: %s\n",
            cudaGetErrorString(cuerr));
        return;
    }

    // синхронизация устройств
    SAFE_CALL(cudaDeviceSynchronize(),
        "Cannot synchronize CUDA kernel: %s\n");

    launchVectorSumShared(xs, size);
}
```

Используется функция редукции из лабораторной работы Vector Sum. 

Еще одна реализация - с интеграцией вычисления положения точек (внутри круга или нет) в первый этап функции редукции. Функция ядра следующая:

```
__global__ void PI_value_reduction_integrated_first_step(double* xs, double* ys, double* output, int size) {
    extern __shared__ double sdata[];
    // each thread loads one element from global to shared mem
    unsigned int tid = threadIdx.x;
    unsigned int i = blockIdx.x * blockDim.x + threadIdx.x;
    if (i < size) {
        double x = xs[i];
        double y = ys[i];
        double v = x * x + y * y;
        sdata[tid] = (v < 1);
    }
    else {
        sdata[tid] = 0;
        return;
    }
    __syncthreads();
    ...
}
```

<h3>Системные средства</h3>
Операционная система – Windows 10 (компилятор NVCC).

<h3>Аппаратные средства</h3>

Центральный процессор – AMD Ryzen 5 3600. Количество ядер – 6. Тактовая частота – 3,6 ГГц или 3600 МГц.

Видеокарта – NVIDIA GeForce GTX 1650. Количество CUDA-ядер – 896. Тактовая частота – 1410 МГц.

<h2>Выбор параметров эксперимента</h2>

Производится сопоставление результатов на предложенных выше реализация при размерах массива 50000, 200000, 1000000.

<h2>Теоретическое предсказание результатов эксперимента</h2>

1) реализация с IF быстрее;
2) реализация с интеграцией определения положения точки внутри/вне круга с первый шаг редукции - быстрее.

<h2>Проведение эксперимента</h2>

Для разных параметров в Visual Studio 2022 запускается код, в котором уже выполнены все необходимые вычисления и получено ускорение. Эти значения выписываются и далее строятся графики.

<h2>Представление результатов</h2>

Результаты представлены рисунках 1-3.

![изображение](https://github.com/RaisssHab/SamaraUniversity-HPC-Fall-2023/assets/60664914/88da4667-bfb4-4881-8323-255d2da27637)

Рисунок 1 – Сравнение параллельных реализаций с CPU-IF.

![изображение](https://github.com/RaisssHab/SamaraUniversity-HPC-Fall-2023/assets/60664914/c94c339b-7131-4448-8d04-4cf075e1f31a)

Рисунок 2 – Сравнение параллельных реализаций с CPU без IF.

![изображение](https://github.com/RaisssHab/SamaraUniversity-HPC-Fall-2023/assets/60664914/12772869-d9b1-4450-9f0f-ef5cc51e88f0)

Рисунок 3 – Совмещенный график.

<h2>Описание результатов</h2>

1.	Реализация с IF быстрее на GPU, но не существенно.
2.	CPU без IF существенно быстрее CPU с IF, из-за чего ускорение на GPU близко к единице.
3.	Реализация с интеграцией определения положения точки внутри/вне круга с первый шаг редукции - быстрее и весьма существенно.

<h2>Анализ результатов</h2>

1. Размер массива, оптимизации компилятора.
2. Не очевидно.
3. Не происходит промежуточного этапа обновления массива xs нулями и единицами, вместо этого отдается исходная пара xs, ys.

<h2>Заключение</h2>

Таким образом, в ходе данной работы была достигнута поставленная цель – проанализировано ускорение параллельной программы на CUDA. 

Теоретические ожидания совпали c практическими результатами, однако непонятно, почему CPU без IF существенно быстрее CPU с IF, из-за чего ускорение на GPU близко к единице.
